{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984f6a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\n08n0\\AppData\\Local\\Temp\\ipykernel_7768\\1456275065.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  with open('D:\\src\\ZEN\\pretrain_data\\stopword\\stopword.txt',encoding='utf-8') as f:\n"
     ]
    }
   ],
   "source": [
    "with open('word_list.txt',encoding='utf-8') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "with open('D:\\src\\ZEN\\pretrain_data\\stopword\\stopword.txt',encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98544505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\n08n0\\AppData\\Local\\Temp\\ipykernel_7768\\2993997350.py:17: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  output_path= 'D:\\src\\ZEN\\pretrain_data\\stopword\\words_list_checked.txt'\n"
     ]
    }
   ],
   "source": [
    "checkedwords = []\n",
    "stop_charactor = set('!@#$%^&*()_+{}|:\"<>?[];,./`~-=\\\\\\'\\\"：（）{}【】、；‘’“”《》？，。') # 需要过滤的字符\n",
    "for word in words:\n",
    "    word,frq = word.split(',')[0],int(word.split(',')[1])\n",
    "\n",
    "    #检查word中是否包含stopword，以及长度是否在2-5之间\n",
    "    flag = True\n",
    "    if len(word) < 2 or len(word) > 5:\n",
    "        flag = False\n",
    "    for stopword in stop_charactor:\n",
    "        if stopword in word:\n",
    "            flag = False\n",
    "            break\n",
    "    if flag:\n",
    "        checkedwords.append([word,frq])\n",
    "\n",
    "output_path= 'D:\\src\\ZEN\\pretrain_data\\stopword\\words_list_checked.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for word, frq in checkedwords:\n",
    "        f.write(f\"{word},{frq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe9a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\n08n0\\AppData\\Local\\Temp\\ipykernel_7768\\2013732503.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  path1 = \"D:\\src\\ZEN\\pretrain_data\\policy\\words_list_checked.txt\"\n",
      "C:\\Users\\n08n0\\AppData\\Local\\Temp\\ipykernel_7768\\2013732503.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  path2 = \"D:\\src\\ZEN\\pretrain_data\\policy\\\\ngram.txt\"\n",
      "C:\\Users\\n08n0\\AppData\\Local\\Temp\\ipykernel_7768\\2013732503.py:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  with open(\"D:\\src\\ZEN\\pretrain_data\\policy\\\\unique_words.txt\", 'w', encoding='utf-8') as f:\n"
     ]
    }
   ],
   "source": [
    "path1 = \"D:\\src\\ZEN\\pretrain_data\\policy\\words_list_checked.txt\"\n",
    "path2 = \"D:\\src\\ZEN\\pretrain_data\\policy\\\\ngram.txt\"\n",
    "\n",
    "# 比较两个文件中，哪些词是独有的，，每一行的格式为“词,频率”\n",
    "# 读取文件1\n",
    "with open(path1, 'r', encoding='utf-8') as f:\n",
    "    file1 = f.readlines()\n",
    "\n",
    "# 读取文件2\n",
    "with open(path2, 'r', encoding='utf-8') as f:\n",
    "    file2 = f.readlines()\n",
    "\n",
    "\n",
    "# 将文件1和文件2中的词存储到集合中\n",
    "words1 = set()\n",
    "for line in file1:\n",
    "    word = line.split(',')[0]\n",
    "    words1.add(word)\n",
    "\n",
    "words2 = set()\n",
    "for line in file2:\n",
    "    word = line.split(',')[0]\n",
    "    words2.add(word)\n",
    "\n",
    "# 找到文件1中独有的词\n",
    "unique_words1 = words1 - words2\n",
    "# 找到文件2中独有的词\n",
    "unique_words2 = words2 - words1\n",
    "\n",
    "# 找到两个文件中都有的词\n",
    "common_words = words1 & words2\n",
    "\n",
    "with open(\"D:\\src\\ZEN\\pretrain_data\\policy\\\\unique_words.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(\"## 独有的词（文件1）:\\n\")\n",
    "    for word in unique_words1:\n",
    "        f.write(word + '\\n')\n",
    "    f.write(\"\\n## 独有的词（文件2）:\\n\")\n",
    "    for word in unique_words2:\n",
    "        f.write(word + '\\n')\n",
    "    f.write(\"\\n## 两个文件都有的词:\\n\")\n",
    "    for word in common_words:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b955a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
